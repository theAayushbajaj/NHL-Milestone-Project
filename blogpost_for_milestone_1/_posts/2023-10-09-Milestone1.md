---
layout: post
title: Milestone 1
---

### Task 1 - Data Acquisition

**Download NHL Data**

In this project, we are given NHL Hockey dataset. The original curated dataset can be accessed through REST API endpoint: https://statsapi.web.nhl.com/api/v1/game/[GAME_ID]/feed/live/. Moreover, 
`GAME_ID` is of `10` digits long. The first 4 represent game's season (e.g. 2017, 2019), the next 2 represent the type of game played (01 = preseason, 02 = regular season, 03 = playoffs, 04 = all-star), and the remaining 4 allude a particular season game.

Given dataset also comprises two game types, i.e. regular and playoff games, which have the following dataset characteristics:
(i) regular seasons: the last 4 digits of `GAME_ID` ranges from 0001 to 1270, which is merely applicable to those seasons with 31 teams, and varies between 0001 and 1230 for those with 30 teams;
(ii) playoff games: the last three digits of `GAME_ID` represent the round, matchup, and game number, respectively.

To acquire (download) the given dataset, we create a class `downloadData` that has two monumental modules:

(a) `download_nhl_raw_data` is responsible to download all the NHL data in accordance with a selected season (or year), given the parent directory path `data_dir_path`. The class `downloadData` receives the user inputs and sets its attributes inside its `constructor` as follows:

```python
class downloadData:
    r"""
    Class to download NHL Hockey Data
    """

    def __init__(self, target_year: str, data_dir_path: str) -> None:
        r"""
        Args:
            target_year (str): The year that we want to get data
            data_dir_path (str): Path to the directory we want to store data (not including year)
        """

        self.target_year = target_year
        self.data_dir_path = data_dir_path
```

Owing to the limitation of data for avaialble seasons, the implemented approach lets the user to download data for five consective seasons, i.e. from 2016-17 to 2020-21.

```python
	def download_nhl_raw_data(self) -> None:
		r"""
		Function to extract NHL games' data for a specific year
		"""

		accessible_years = ['2016', '2017', '2018', '2019', '2020', '2021']
		
		if(self.target_year not in accessible_years):
			print("Dataset does not contain the entered year")
```

Here, the user-selected year is being matched with the available years for validity. Once the year's validity has been confirmed, we initialize paths for the two given game types with the arguments provided, following which essential directories are created in case they do not exist already.

```python
		# Initializing regular and playoff settings' path
		regular_dir_path = os.path.join(self.data_dir_path, self.target_year, 'regular_games')
		playoff_dir_path = os.path.join(self.data_dir_path, self.target_year, 'playoff_games')

		# Sanity check for directories's existence
		if not os.path.exists(regular_dir_path):
			os.makedirs(regular_dir_path)
		if not os.path.exists(playoff_dir_path):
			os.makedirs(playoff_dir_path)
```

The following snippet is to download all the relevant data files for `regular` game type for the user-provided target year (season):

```python
		# Download data of regular games for the selected year
		print(f'Downloading regular games data for {self.target_year}...')

		# Year 2016 has 1230 games, while the remaining available years have data of 1270 games
		ID_range = 1231 if (self.target_year=='2016') else 1271

		for ID in tqdm(range(1, ID_range)):
			# Convert ID from integer to string
			ID_str =  "0" * (4 - len(str(ID))) + str(ID)
			regular_game_id = self.target_year + "02" + ID_str
			
			# Download data of each game
			self.download_nhl_data(regular_dir_path, regular_game_id)
```

It is worth mentioning that for 2016, we have 30 teams with total of 1230 games, whereas for each season following 2016, total of 1270 games were played with engagement of 31 teams.

```python
		# Download data of playoff games for the selected year
		print(f"Downloading playoff games data for {self.target_year}...")

		for round in tqdm(range(1, 5)):
			# `round 1` comprises `8` game matchups, `round 2` has game matchups of `4` and so on
			matchups = int(2**(3 - round))
			for matchup_number in range(1, matchups + 1):
				# Each match up has 7 games in total
				for game_id in range(1, 8):
					playoff_game_id = self.target_year + "030" + str(round) + str(matchup_number) + str(game_id)
					self.download_nhl_data(playoff_dir_path, playoff_game_id)
```				

(b) We also create a utility function named `download_nhl_data`	that is responsible for downloading a specific game's data from the provided NHL Data API given `NHL Game ID`.

```python
	def download_nhl_data(self, path: str, nhl_game_id: str) -> None:
		r"""
        Download NHL play-by-play data of a specific game into a particular directory path

        Args:
            path: Path to the directory
            nhl_game_id: Game ID of the NHL game that we want to download the data of
        """

		file_path = os.path.join(path, nhl_game_id + ".json")
		
		# Return if file path already exists
		if(os.path.exists(file_path)):
				return
			
		try:
			# Read NHL play-by-play data for both regular season and playoffs game settings
			with urllib.request.urlopen("https://statsapi.web.nhl.com/api/v1/game/" + nhl_game_id + "/feed/live/") as url:
				data = json.load(url)
				if ("messageNumber" in data and "message" in data 
					and data["messageNumber"] == 2 and data["message"] == "Game data couldn't be found"):
					pass
				else:
					with open(file_path, 'w') as outfile:
						json.dump(data, outfile)
		except HTTPError as he:
			print(nhl_game_id)
			print(he.reason)
		except Exception:
			print('nhl_game_id: '+str(nhl_game_id))
			e_type, e_value, e_traceback = sys.exc_info()
			print(e_value)		
```
				
Voila!! All the necessary functions that could aid in downloading and structuring the NHL data have been prepared. Running the following short code snippet will collect and arrange the data of all seasons (starting 2016 to 2021) to the parent folder "/data/raw_data":

```python
download_path = os.path.join("data", "raw_data")
available_years = ['2016', '2017', '2018', '2019', '2020', '2021']
for year in available_years:
	obj = downloadData(year, download_path)
    obj.download_nhl_raw_data()
```				

The above snippet can be run for any number of times. Note that running the above snippet only download the missing data files and skip the existing data files upon its multiple executions to ensure having all data downloaded and arranged properly using NHL Stats API.

It's worth noticing that since we have two game types (`regular` and `playoff`) for each season, te above code snippet upon execution results in the following data directory structure:

```python
-- /data/raw
    -- 2016
    -- 2017
    -- 2018
    -- 2019
        -- playoff_games
            -- [gameId1].json
            -- [gameId2].json
        -- regular_games
            -- [gameId3].json
            -- [gameId4].json
    -- 2020
	-- 2021
```

### Task 2 - Tidy Data
The schema of the data from json files look like this:

